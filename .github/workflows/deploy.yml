name: Deploy Portfolio to Production Server

on:
  push:
    branches:
      - main

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: photography-portfolio
  SERVER_APP_DIR: /opt/portfolio-app
  SERVICE_NAME: portfolio-app.service

jobs:
  build-and-push-image:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      image_uri: ${{ steps.get-primary-tag.outputs.primary_tag }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set lowercase image owner
        run: echo "IMAGE_OWNER_LC=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
        shell: bash
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_OWNER_LC }}/${{ env.IMAGE_NAME }}
          tags: |
            type=sha,prefix=,format=short
            type=raw,value=latest,enable=${{ github.ref == format('refs/heads/{0}', 'main') }}
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      - name: Get primary image tag
        id: get-primary-tag
        run: |
          PRIMARY_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n 1)
          echo "primary_tag=$PRIMARY_TAG" >> $GITHUB_OUTPUT
        shell: bash

  deploy-to-server:
    name: Deploy to Production Server
    runs-on: ubuntu-latest
    needs: build-and-push-image
    environment: production
    steps:
      - name: Set up SSH key
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}
      - name: Prepare Deployment Files
        id: prepare-files
        run: |
          # Prepare docker-compose file and base64 encode it
          COMPOSE_CONTENT_B64=$(cat <<EOF | base64 -w 0
          version: "3.8"
          services:
            portfolio-app:
              image: "${{ needs.build-and-push-image.outputs.image_uri }}"
              container_name: portfolio-app
              restart: unless-stopped
              env_file: .env
              ports:
                - "8000:8000"
              networks:
                - portfolio-net
          networks:
            portfolio-net:
              driver: bridge
          EOF
          )
          echo "compose_file_b64=${COMPOSE_CONTENT_B64}" >> $GITHUB_OUTPUT

          # Prepare Python OCI connection check script and base64 encode it
          CHECK_SCRIPT_B64=$(cat <<'EOF' | base64 -w 0
          import os
          import boto3
          from botocore.exceptions import ClientError, NoCredentialsError

          def check_oci_connection():
              """Checks the connection to OCI Object Storage and validates the bucket."""
              bucket_name = os.getenv('OCI_BUCKET_NAME')
              endpoint_url = os.getenv('OCI_ENDPOINT_URL')
              region = os.getenv('OCI_REGION')
              access_key = os.getenv('OCI_ACCESS_KEY_ID')
              
              print("--- OCI Connection Check ---")
              print(f"Endpoint URL: {endpoint_url}")
              print(f"Region: {region}")
              print(f"Bucket Name: {bucket_name}")
              print(f"Access Key ID: {access_key}")
              
              if not all([bucket_name, endpoint_url, region, access_key, os.getenv('OCI_SECRET_ACCESS_KEY')]):
                  print("\n[ERROR] One or more required OCI environment variables are not set.")
                  exit(1)
              
              try:
                  s3_client = boto3.client(
                      's3',
                      endpoint_url=endpoint_url,
                      aws_access_key_id=access_key,
                      aws_secret_access_key=os.getenv('OCI_SECRET_ACCESS_KEY'),
                      region_name=region
                  )
                  
                  print("\nAttempting to connect and verify bucket...")
                  s3_client.head_bucket(Bucket=bucket_name)
                  print("\n[SUCCESS] Connection successful and bucket exists.")
                  print("----------------------------")
              
              except NoCredentialsError:
                  print("\n[ERROR] Credentials not found. Ensure OCI_ACCESS_KEY_ID and OCI_SECRET_ACCESS_KEY are set.")
                  exit(1)
              except ClientError as e:
                  error_code = e.response.get("Error", {}).get("Code")
                  print(f"\n[ERROR] A client error occurred: {error_code}")
                  if error_code == '404':
                      print(f"  - The bucket '{bucket_name}' was not found at the specified endpoint and region.")
                  elif error_code == '403':
                      print("  - Access denied. Check IAM policies and credentials.")
                  else:
                      print(f"  - Details: {e}")
                  exit(1)
              except Exception as e:
                  print(f"\n[ERROR] An unexpected error occurred: {e}")
                  exit(1)

          if __name__ == '__main__':
              check_oci_connection()
          EOF
          )
          echo "check_script_b64=${CHECK_SCRIPT_B64}" >> $GITHUB_OUTPUT
      - name: Deploy via SSH
        env:
          TARGET_SSH_HOST: ${{ secrets.SSH_HOST }}
          TARGET_SSH_USER: ${{ secrets.SSH_USER }}
          GHCR_PULL_TOKEN: ${{ secrets.GHCR_PULL_TOKEN }}
          GHCR_USERNAME: ${{ github.repository_owner }}
          # --- OCI Secrets ---
          OCI_ENDPOINT_URL: ${{ secrets.OCI_ENDPOINT_URL }}
          OCI_REGION: ${{ secrets.OCI_REGION }}
          OCI_ACCESS_KEY_ID: ${{ secrets.OCI_ACCESS_KEY_ID }}
          OCI_SECRET_ACCESS_KEY: ${{ secrets.OCI_SECRET_ACCESS_KEY }}
          OCI_BUCKET_NAME: ${{ secrets.OCI_BUCKET_NAME }}
          # --- Base64 Encoded Files ---
          COMPOSE_FILE_B64: ${{ steps.prepare-files.outputs.compose_file_b64 }}
          CHECK_SCRIPT_B64: ${{ steps.prepare-files.outputs.check_script_b64 }}
        run: |
          ssh-keyscan -H "${TARGET_SSH_HOST}" >> ~/.ssh/known_hosts
          ssh -o StrictHostKeyChecking=no "${TARGET_SSH_USER}@${TARGET_SSH_HOST}" << EOF
            set -ex

            # --- 1. Debugging: Display configuration (secrets are masked by GitHub Actions) ---
            echo "### Starting Deployment ###"
            echo "Server App Directory: ${{ env.SERVER_APP_DIR }}"
            echo "Service Name: ${{ env.SERVICE_NAME }}"
            echo "OCI Endpoint URL: ${{ env.OCI_ENDPOINT_URL }}"
            echo "OCI Region: ${{ env.OCI_REGION }}"
            echo "OCI Bucket Name: ${{ env.OCI_BUCKET_NAME }}"

            # --- 2. Pre-flight Check: Verify OCI Connection ---
            sudo apt-get update
            sudo apt-get install -y python3-boto3
            echo "${CHECK_SCRIPT_B64}" | base64 -d > /tmp/check_oci.py
            
            # Export secrets for the check script to use
            export OCI_ENDPOINT_URL="${OCI_ENDPOINT_URL}"
            export OCI_REGION="${OCI_REGION}"
            export OCI_ACCESS_KEY_ID="${OCI_ACCESS_KEY_ID}"
            export OCI_SECRET_ACCESS_KEY="${OCI_SECRET_ACCESS_KEY}"
            export OCI_BUCKET_NAME="${OCI_BUCKET_NAME}"
            
            python3 /tmp/check_oci.py
            rm /tmp/check_oci.py

            # --- 3. Prepare Server Environment ---
            sudo mkdir -p ${{ env.SERVER_APP_DIR }}
            {
              echo "OCI_ENDPOINT_URL=${OCI_ENDPOINT_URL}"
              echo "OCI_REGION=${OCI_REGION}"
              echo "OCI_ACCESS_KEY_ID=${OCI_ACCESS_KEY_ID}"
              echo "OCI_SECRET_ACCESS_KEY=${OCI_SECRET_ACCESS_KEY}"
              echo "OCI_BUCKET_NAME=${OCI_BUCKET_NAME}"
              echo "FLASK_ENV=production"
            } | sudo tee ${{ env.SERVER_APP_DIR }}/.env > /dev/null
            sudo chmod 600 ${{ env.SERVER_APP_DIR }}/.env

            # Decode the base64 content and write the compose file
            echo "${COMPOSE_FILE_B64}" | base64 -d | sudo tee ${{ env.SERVER_APP_DIR }}/docker-compose.yml > /dev/null

            # --- 4. Pull New Image ---
            echo "${GHCR_PULL_TOKEN}" | sudo docker login ghcr.io -u "${GHCR_USERNAME}" --password-stdin
            cd ${{ env.SERVER_APP_DIR }}
            sudo docker compose pull

            # --- 5. Create/Update and Restart Systemd Service ---
            echo "[Unit]" | sudo tee /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "Description=Portfolio App Service" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "Requires=docker.service" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "After=docker.service network.target" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "[Service]" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "WorkingDirectory=${{ env.SERVER_APP_DIR }}" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "Restart=always" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "ExecStart=/usr/bin/docker compose up" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "ExecStop=/usr/bin/docker compose down" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "[Install]" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}
            echo "WantedBy=multi-user.target" | sudo tee -a /etc/systemd/system/${{ env.SERVICE_NAME }}

            sudo systemctl daemon-reload
            sudo systemctl enable ${{ env.SERVICE_NAME }}
            sudo systemctl restart ${{ env.SERVICE_NAME }}

            # --- 6. Clean up ---
            sudo docker image prune -f

            echo "### Deployment finished successfully. ###"
          EOF
        shell: bash